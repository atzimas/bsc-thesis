@article{,
   author = {Mirjana Pejić-Bach and Ivan Jajić and Tanja Kamenjarska},
   doi = {10.1016/j.procs.2023.01.268},
   issn = {18770509},
   journal = {Procedia Computer Science},
   pages = {91-98},
   title = {A Bibliometric Analysis of Phishing in the Big Data Era: High Focus on Algorithms and Low Focus on People},
   volume = {219},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050923002764},
   year = {2023},
}
@generic{Guembe2022,
   abstract = {Cyberattacks are becoming more sophisticated and ubiquitous. Cybercriminals are inevitably adopting Artificial Intelligence (AI) techniques to evade the cyberspace and cause greater damages without being noticed. Researchers in cybersecurity domain have not researched the concept behind AI-powered cyberattacks enough to understand the level of sophistication this type of attack possesses. This paper aims to investigate the emerging threat of AI-powered cyberattacks and provide insights into malicious used of AI in cyberattacks. The study was performed through a three-step process by selecting only articles based on quality, exclusion, and inclusion criteria that focus on AI-driven cyberattacks. Searches in ACM, arXiv Blackhat, Scopus, Springer, MDPI, IEEE Xplore and other sources were executed to retrieve relevant articles. Out of the 936 papers that met our search criteria, a total of 46 articles were finally selected for this study. The result shows that 56% of the AI-Driven cyberattack technique identified was demonstrated in the access and penetration phase, 12% was demonstrated in exploitation, and command and control phase, respectively; 11% was demonstrated in the reconnaissance phase; 9% was demonstrated in the delivery phase of the cybersecurity kill chain. The findings in this study shows that existing cyber defence infrastructures will become inadequate to address the increasing speed, and complex decision logic of AI-driven attacks. Hence, organizations need to invest in AI cybersecurity infrastructures to combat these emerging threats.},
   author = {Blessing Guembe and Ambrose Azeta and Sanjay Misra and Victor Chukwudi Osamor and Luis Fernandez-Sanz and Vera Pospelova},
   doi = {10.1080/08839514.2022.2037254},
   issn = {10876545},
   issue = {1},
   journal = {Applied Artificial Intelligence},
   publisher = {Taylor and Francis Ltd.},
   title = {The Emerging Threat of Ai-driven Cyber Attacks: A Review},
   volume = {36},
   year = {2022},
}
@article{Shahriar2011,
   abstract = {Most web programs are vulnerable to cross site scripting (XSS) that can be exploited by injecting JavaScript code. Unfortunately, injected JavaScript code is difficult to distinguish from the legitimate code at the client side. Given that, server side detection of injected JavaScript code can be a layer of defense. Existing server side approaches rely on identifying legitimate script code, and an attacker can circumvent the technique by injecting legitimate JavaScript code. Moreover, these approaches assume that no JavaScript code is downloaded from third party websites. To address these limitations, we develop a server side approach that distinguishes injected JavaScript code from legitimate JavaScript code. Our approach is based on the concept of injecting comment statements containing random tokens and features of legitimate JavaScript code. When a response page is generated, JavaScript code without or incorrect comment is considered as injected code. Moreover, the valid comments are checked for duplicity. Any presence of duplicate comments or a mismatch between expected code features and actually observed features represents JavaScript code as injected. We implement a prototype tool that automatically injects JavaScript comments and deploy injected JavaScript code detector as a server side filter. We evaluate our approach with three JSP programs. The evaluation results indicate that our approach detects a wide range of code injection attacks. © 2011 IEEE.},
   author = {Hossain Shahriar and Mohammad Zulkernine},
   doi = {10.1109/COMPSACW.2011.27},
   isbn = {9780769544595},
   issn = {07303157},
   journal = {Proceedings - International Computer Software and Applications Conference},
   keywords = {Comment injection,JavaScript code injection},
   pages = {104-109},
   title = {Injecting comments to detect javascript code injection attacks},
   year = {2011},
}
@article{Fard2013,
   abstract = {JavaScript is a powerful and flexible prototypebased scripting language that is increasingly used by developers to create interactive web applications. The language is interpreted, dynamic, weakly-typed, and has first-class functions. In addition, it interacts with other web languages such as CSS and HTML at runtime. All these characteristics make JavaScript code particularly error-prone and challenging to write and maintain. Code smells are patterns in the source code that can adversely influence program comprehension and maintainability of the program in the long term. We propose a set of 13 JavaScript code smells, collected from various developer resources. We present a JavaScript code smell detection technique called JSNOSE. Our metric-based approach combines static and dynamic analysis to detect smells in client-side code. This automated technique can help developers to spot code that could benefit from refactoring. We evaluate the smell finding capabilities of our technique through an empirical study. By analyzing 11 web applications, we investigate which smells detected by JSNOSE are more prevalent. © 2013 IEEE.},
   author = {Amin Milani Fard and Ali Mesbah},
   doi = {10.1109/SCAM.2013.6648192},
   isbn = {9781467357395},
   journal = {IEEE 13th International Working Conference on Source Code Analysis and Manipulation, SCAM 2013},
   keywords = {JavaScript,code smell,smell detection,web applications},
   pages = {116-125},
   publisher = {IEEE Computer Society},
   title = {JSNOSE: Detecting javascript code smells},
   year = {2013},
}
@article{Yahva2021,
   abstract = {JavaScript plays an important role in web applications and services, which is used by millions of web pages in optimizing interface design, embedding dynamic texts, reading and writing HTML elements, validating form data, responding to browser events, controlling cookies and much more. However, since JavaScript is cross-platform and can be executed dynamically, it has been a major vehicle for web-based attacks. Existing solutions work by performing static analysis or monitoring program execution dynamically. However, since the heavy use of obfuscation techniques, many methods no longer apply to malicious JavaScript code detection, and it has been a huge challenge to de-obfuscate obfuscated malicious JavaScript code accurately. In this paper, we propose a hybrid analysis method combining static and dynamic analysis for detecting malicious JavaScript code that works by first conducting syntax analysis and dynamic instrumentation to extract internal features that are related to malicious code and then performing classificationbased detection to distinguish attacks. In addition, based on code instrumentation, we propose a new method which can deobfuscate part of obfuscated malicious JavaScript code accurately. Ultimately, we implement a browser plug-in called MJDetector and perform evaluation on 450 real web pages. Evaluation results show that our method can detect malicious JavaScript code and de-obfuscate obfucation effectively and efficiently. Specifically, MJDetector can detect JavaScipt attacks in current web pages with high accuracy 94.76% and de-obfuscate obfuscate code of specific types with accuracy 100% whereas the base line method can only detect with accuracy 81.16% and has no capacity of de-obfuscation.},
   author = {Xincheng He and Lei Xu and Chunliu Cha},
   doi = {10.1109/APSEC.2018.00051},
   isbn = {9781728119700},
   issn = {15301362},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {De-obfuscation,Hybrid Analysis,Machine Learning,Malicious Code Detection},
   month = {7},
   pages = {365-374},
   publisher = {IEEE Computer Society},
   title = {Malicious JavaScript Code Detection Based on Hybrid Analysis},
   volume = {2018-December},
   year = {2018},
}
@article{Fa2017,
   abstract = {JavaScript can modify HyperText Markup Language(HTML) code. <iframe> tag of HTML can load pages from other websites. These technologies are widely used nowadays for constructing flexible and robust web services. However, illegal websites also use these technologies to hide illegal contents. For traditional methods using web text to detect these illegal webpages (just getting initial source codes that aren't parsed by a browser), they can't give a precise judgment. In this paper, we solved the challenge and proposed a robust Internet abuse detection method. We get HTML codes that had been parsed by simulating the progress how browsers work in order to gather the necessary materials for text detection methods. Besides, we not only extracted the text features of HTML code, but also extracted structure features of HTML codes. With the experiments under detecting Internet abuse scenarios, we demonstrated that the proposal is efficient.},
   author = {Zhou Fa and Guang Gang Geng and Zhi Wei Yan and Xiao Dong Lee},
   doi = {10.1109/BIGDATA.2017.8258113},
   isbn = {9781538627143},
   journal = {Proceedings - 2017 IEEE International Conference on Big Data, Big Data 2017},
   keywords = {Internet abuse,Text mining},
   month = {7},
   pages = {1712-1715},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A robust internet abuse detection method},
   volume = {2018-January},
   year = {2017},
}
@article{Li2021,
   abstract = {With the implementation of the strategy of 'three types and two networks', there are network security risks in every link of the power system, which is mainly reflected in the fact that the power information system has a large user base and large exposure, and at the same time stores a large amount of electricity customer data. bearing control business, once the system is breached, it will have a great impact on the society and economy. However, the network attack on power information system has the characteristics of 'strong professionalism, deep latency, long persistence and great destructiveness', so the security monitoring of power network and information system is faced with great challenges. Attackers generally use malicious programs to steal sensitive information, but with the progress of various intrusion detection technologies, malicious program anti-detection technology is also developing, which makes malicious program traffic very hidden and more difficult to be detected. Based on the shallow machine learning method, the ability to describe the characteristics of malicious programs is insufficient, and in the face of new malicious programs, such as inefficiency or failure, deep learning technology shows a strong learning ability in many application fields. this paper explores the research and application of malicious program traffic monitoring technology based on deep learning method. This paper studies the monitoring of abnormal traffic access behavior of malicious programs based on deep learning, and perceives abnormal traffic and security threats in real time.},
   author = {Feng Li and Jianye Zhang and Bizhou He and Bin Wang and Shu Ting Chen},
   doi = {10.1109/ICIBA52610.2021.9688195},
   isbn = {9781665428767},
   journal = {Proceedings of 2021 IEEE 2nd International Conference on Information Technology, Big Data and Artificial Intelligence, ICIBA 2021},
   keywords = {Deep learning,Flow detection,Malicious program,Real time monitoring},
   pages = {762-765},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Research on malicious Program Traffic Detection Technology based on Deep Learning},
   year = {2021},
}
@article{Pradeepa2022,
   abstract = {Malicious web pages are well-known threats in cyberspace. Malicious webpages and their URLs appear to be legitimate webpages in cyberspace and are used to steal personal information from internet users (victims) or to install malicious software on the victim's machine in order to gain further access and make the victims more vulnerable in cyberspace. Identifying such web pages in cyberspace is a difficult task for internet users. Researchers use different techniques with different sets of features to detect malicious web pages in cyberspace. Most of them extract vital features from URL text for malicious webpage classification due to their simplicity and risk-free nature. Some of them extract the limited number of features from the webpage content for better classification along with other features. Our proposed system considers features that are extracted only from the webpage content and use a machine learning model for classification. The accuracy of the existing and proposed systems is demonstrated experimentally. The result shows that the proposed system is more efficient.},
   author = {G. Pradeepa and R. Devi},
   doi = {10.1109/ICIRCA54612.2022.9985597},
   isbn = {9781665497077},
   journal = {4th International Conference on Inventive Research in Computing Applications, ICIRCA 2022 - Proceedings},
   keywords = {Feature extraction,Machine Learning,Malicious Uniform Resource Locator classification,Malicious webpage detection},
   pages = {189-193},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Web Content Based Features for Malicious Web Page Detection Using Machine Learning},
   year = {2022},
}
@article{Purwanti2018,
   abstract = {Health information data is the only thing to know by doctors and the hospital, if the patient's medical record information is disseminated it can cause adverse effects for the patient. This study aims to analyze the impact of MITM (Man In The Middle) attacks on patient privacy data. Data is sent and attacked by MITM active attack method. The experimental results show that the unprotected data and the MD5-protected data are able to be successfully modified within 3 minutes and 2 minutes and 4.2 seconds respectively. The experimental data on the comparison of security mechanisms between MD5 and SHA512, indicates that for SHA512, the attacker can only do a phishing password but can not modify the data. As for MD5, in addition to phishing password and then steal the data, the attacker is also able to read and modify data with a minimum of 9 characters of data characters in 3 minutes 3 seconds, the rest of the data still can not be cracked / burglarized so it can not be modified.},
   author = {Sirep Purwanti and Beny Nugraha and Mudrik Alaydrus},
   doi = {10.1109/BCWSP.2017.8272557},
   isbn = {9781538628324},
   journal = {2017 International Conference on Broadband Communication, Wireless Sensors and Powering, BCWSP 2017},
   keywords = {HL7,MD5,MITM,Phising,SHA5I2},
   month = {1},
   pages = {1-4},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Enhancing security on E-health private data using SHA-512},
   volume = {2018-January},
   year = {2018},
}
@article{Patil2017,
   abstract = {Phishing is a criminal scheme to steal the user's personal data and other credential information. It is a fraud that acquires victim's confidential information such as password, bank account detail, credit card number, financial username and password etc. and later it can be misuse by attacker. We aim to use fundamental visual features of a web page's appearance as the basis of detecting page similarities. We propose a novel solution, to efficiently detect phishing web pages. Note that page layouts and contents are fundamental feature of web pages' appearance. Since the standard way to specify page layouts is through the style sheet (CSS), we develop an algorithm to detect similarities in key elements related to CSS. In this paper, we proposed a system that uses SVM technique along with map-reduce paradigm to achieve a higher accuracy in detection of the spam email. By using the map-reduce technique we also try to overcome the two hurdles of the SVM.},
   author = {Prajakta Patil and Rashmi Rane and Madhuri Bhalekar},
   doi = {10.1109/ICISC.2017.8068633},
   isbn = {9781509047154},
   journal = {Proceedings of the International Conference on Inventive Systems and Control, ICISC 2017},
   keywords = {CSS,Map Reduce,Phising,SVM,Spam},
   month = {10},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Detecting spam and phishing mails using SVM and obfuscation URL detection algorithm},
   year = {2017},
}
@article{Yahva22021,
   abstract = {As the world responded to the Coronavirus Disease 2019 (COVID-19) pandemic in 2020, digital operations became more important, and people started to depend on new initiatives such as the cloud and mobile infrastructure. Consequently, the number of cyberattacks such as phishing has increased. Phishing websites can be detected using machine learning by classifying the websites into legitimate or illegitimate websites. The purpose of the study is to conduct a mini-review of the existing techniques and implement experiments to detect whether a website is malicious or not. The dataset consists of 11,055 observations and 32 variables. Three supervised learning models are implemented in this study: Decision Tree, K-Nearest Neighbour (KNN), and Random Forest. The three algorithms are chosen because it provides a better understanding and more suitable for the dataset. Based on the experiments undertaken, the result shows Decision Tree has an accuracy of 91.16% which is the lowest compared to the other models, 97.6% for the KNN model which is the highest among all the models and 94.44% accuracy for the Random Forest model. Through comparisons between the three models, KNN was the prime candidate for the best model considering that it has the highest accuracy. However, Random Forest is deemed more suitable for the dataset even though the accuracy is lesser because of the lowest false-negative value than the other models. The experiments can be further investigated with different datasets and models for comparative analysis.},
   author = {Farashazillah Yahva and Ryan Isaac W. Mahibol and Chong Kim Ying and Magnus Bin Anai and Sidney Allister Frankie and Eric Ling Nin Wei and Rio Guntur Utomo},
   doi = {10.1109/ICODSA53588.2021.9617482},
   isbn = {9781665443036},
   journal = {2021 International Conference on Data Science and Its Applications, ICoDSA 2021},
   keywords = {machine learning,malicious URL,phishing,prediction,website},
   pages = {40-47},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Detection of Phising Websites using Machine Learning Approaches},
   year = {2021},
}
@article{Swarnalatha2021,
   abstract = {Now-a-days there are different types of cybercrime, Phishing is one of cyber-attacks where attackers impersonate as a member of legitimate institutions or organizations through an email, text message, advertisements or through any means to steal sensitive information which results to loss of personal and sensitive information such as account no, social security no, credit card no etc.. Phishing attack has been increasing exponentially. In this attack mostly innocent users are comes to losses their sensitive, unique, personal, valuable and secure data and information's. Many hackers are accomplished through phishing attacks where client are trapped into interacting with web-pages which looks like to be legitimate websites. The websites exactly seems to be semantically as well as visually to the original websites. The main idea of the phisher or hackers is to gain and purloin the critical information such as credential account, username, password and other private information related to any organization and company. According to phishing or web spoofing techniques is one examples of social engineering attack. Phishers are appears in many platform of communication such as in the form of VOIP, message and e-mails which is not real. Commonly users have many accounts on various websites including social media, email, and also in bank. So that innocent users are the most vulnerable targets for these types of attack. This happened because most of the peoples are unknown of the sensitive data, which helps them to get their information successfully. As of 2020, phishing is the most common attack performed by cyber criminals according to FBI's Internet Crime Complaint Centre. First phishing Datasets are collected from phish tank and then legitimate websites are collected from University of New Brunswick and then dataset is preprocessed using wrapper and filter method so that it covers the dataset which gets missed, tampered and unstructured.},
   author = {K. S. Swarnalatha and K. C. Ramchandra and Kaushar Ansari and Love Ojha and Sanjok Subedi Sharma},
   doi = {10.1109/CSITSS54238.2021.9683237},
   isbn = {9781665406109},
   journal = {CSITSS 2021 - 2021 5th International Conference on Computational Systems and Information Technology for Sustainable Solutions, Proceedings},
   keywords = {Hackers,Legitimate,Phisher,Phishing attack,Sensitive data.},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Real-Time Threat Intelligence-Block Phising Attacks},
   year = {2021},
}
@article{Gupta2016,
   abstract = {On the World Wide Web, the malicious links are highly problematic in the dissemination channels as a source code to the malware broadcasting. These suspicious malicious links gives full access to the web attackers as an instrument of web pages on internet. It is easily affected by the results of attackers on the system of victim where system is utilized easily for performing the cyber-attacks such as stealing the financial credentials, phishing-spamming, hacking and many more such web attacks. The developed system must be accurate and fast enough to detect these types of such cyber-attacks by observing the ability to find new developed malicious URLs or malicious source code contents. It is the critical task to detect the malicious contents in network of the web pages over the World Wide Web. The various malicious cyber-attacks like spamming, code phishing are done by using the malicious URLs to mount these types of cyber-attacks. Internet unlawful activities are found in Malicious Web sites as cornerstone of the Malicious URLs. The main threat is to identify these attacks so that the suspicious URLs can be easily resolved as malicious URLs along with its source code of the web pages. In this paper, a method has been proposed which is highly useful in the field of World Wide Web networking of domains for detecting the malicious URLs by using BM (Boyer-Moore) [1] string pattern matching algorithm based on word segmentation approach [2]. The nature of attacks is identified as a malicious URL or source code of the web sites questioned on the World Wide Web. The proposed approach is based on the real time system for getting suspicious URL from the DNS server followed by the detection on the basis of word segmentation of source code. The discriminative features of this system are verified by using the proposed method which gives a variety of properties including text and link in the source code as highly powerful and novel approach in the detection of suspicious URLs.},
   author = {Sachin Gupta},
   doi = {10.1109/ICRAIE.2016.7939534},
   isbn = {9781509028078},
   journal = {2016 International Conference on Recent Advances and Innovations in Engineering, ICRAIE 2016},
   keywords = {BM (Boyer-Moore) Pattern,Classification Module,Malicious Web Pages,Web-Based Attacks},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Efficient malicious domain detection using word segmentation and BM pattern matching},
   year = {2016},
}
@article{Zhang2014,
   abstract = {Security risks brought by web page information has been a matter that can no longer be ignored. Malicious script is a major challenge the web sites security is facing currently. According to the data from the Google Research Centre, more than 10% of web pages is malicious. Especially in China, the proportion of malicious web pages has reached 43.21%. This paper presents a detection system which is used to locate the malicious scripts in web pages. It acquires and builds up malicious code features base, URL of hidden links base etc. based on safety data published on security research web sites. The web crawler is applied to collecting web pages source code in this system and learning algorithm for classification is used to train the classifier. The classification results would be evaluated and improved in the end.},
   author = {Siyue Zhang and Weiguang Wang and Zhao Chen and Heng Gu and Jianyi Liu and Cong Wang},
   doi = {10.1109/CCIS.2014.7175767},
   isbn = {9781479947201},
   journal = {CCIS 2014 - Proceedings of 2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems},
   keywords = {Crawler,Hidden link,Malicious script,Script detection},
   pages = {394-399},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A web page malicious script detection system},
   year = {2014},
}
@article{Biddle2009,
   abstract = {There has been a loss of confidence in the security provided by SSL certificates and browser interfaces in the face of various attacks. As one response, basic SSL server certificates are being demoted to second-class status in conjunction with the introduction of Extended Validation (EV) SSL certificates. Unfortunately, EV SSL certificates may complicate the already difficult design challenge of effectively conveying certificate information to the average user. This study explores the interfaces related to SSL certificates in the most widely deployed browser (Internet Explorer 7), proposes an alternative set of interface dialogs, and compares their effectiveness through a user study involving 40 participants. The alternative interface was found to offer statistically significant improvements in confidence, ease of finding information, and ease of understanding. Such results from a modest re-design effort suggest considerable room for improvement in the user interfaces of browsers today. This work motivates further study of whether EV SSL certificates offer a robust foundation for improving Internet trust, or a further compromise to usable security for ordinary users. Copyright 2009 ACM.},
   author = {Robert Biddle and P. C. Van Oorschot and Andrew S. Patrick and Jennifer Sobey and Tara Whalen},
   doi = {10.1145/1655008.1655012},
   isbn = {9781605587844},
   issn = {15437221},
   journal = {Proceedings of the ACM Conference on Computer and Communications Security},
   keywords = {Browser user interfaces,Extended validation,SSL certificates,Usability and security,User study,Web site identity},
   pages = {19-30},
   title = {Browser interfaces and extended validation SSL certificates: An empirical study},
   year = {2009},
}
@article{Stojmenovic2019,
   abstract = {Users are used to authenticating themselves to websites, but not for websites to authenticate to them. One readily available mechanism that may help users make safer online decisions lies in website certificates that contain website identity information. Fraudulent websites are now short-lived and present valid certificates without any identity information. Our goal was to create and test the effectiveness of simpler certificate interfaces, made to help users differentiate between identity-verified websites and those without such verification, and thus, potentially fraudulent. We conducted a study with a certificate interface prototype with simple identity notification types. Our findings suggest that presenting identity information to users can help them differentiate between real and potentially fraudulent websites. Some users were suspicious of the notifications and incorrectly felt that they could make decisions based on website appearance, so building user background knowledge is essential.},
   author = {Milica Stojmenovic and Eric Spero and Temitayo Oyelowo and Robert Biddle},
   doi = {10.1109/PST47121.2019.8949048},
   isbn = {9781728132655},
   journal = {2019 17th International Conference on Privacy, Security and Trust, PST 2019 - Proceedings},
   keywords = {Usable website certificate interface,notifications},
   month = {8},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Website Identity Notification: Testing the Simplest Thing That Could Possibly Work},
   year = {2019},
}
@article{Zabihimayvan2019,
   abstract = {Phishing as one of the most well-known cybercrime activities is a deception of online users to steal their personal or confidential information by impersonating a legitimate website. Several machine learning-based strategies have been proposed to detect phishing websites. These techniques are dependent on the features extracted from the website samples. However, few studies have actually considered efficient feature selection for detecting phishing attacks. In this work, we investigate an agreement on the definitive features which should be used in phishing detection. We apply Fuzzy Rough Set (FRS) theory as a tool to select most effective features from three benchmarked data sets. The selected features are fed into three often used classifiers for phishing detection. To evaluate the FRS feature selection in developing a generalizable phishing detection, the classifiers are trained by a separate out-of-sample data set of 14,000 website samples. The maximum F-measure gained by FRS feature selection is 95% using Random Forest classification. Also, there are 9 universal features selected by FRS over all the three data sets. The F-measure value using this universal feature set is approximately 93% which is a comparable result in contrast to the FRS performance. Since the universal feature set contains no features from third-part services, this finding implies that with no inquiry from external sources, we can gain a faster phishing detection which is also robust toward zero-day attacks.},
   author = {Mahdieh Zabihimayvan and Derek Doran},
   doi = {10.1109/FUZZ-IEEE.2019.8858884},
   isbn = {9781538617281},
   issn = {10987584},
   journal = {IEEE International Conference on Fuzzy Systems},
   keywords = {Feature Selection,Fuzzy Rough Set,Phishing Detection},
   month = {6},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Fuzzy Rough Set Feature Selection to Enhance Phishing Attack Detection},
   volume = {2019-June},
   year = {2019},
}
@article{Wang2022,
   abstract = {Feature selection is a useful dimension reduction method in data preprocessing for machine learning. It is an discrete optimization problem in essence. Genetic algorithm is a meta heuristic optimization algorithm for discrete optimization problem, which simulates the biological evolution behavior in nature. The original Genetic algorithm, like many other swarm intelligence optimization algorithms, has its own defects, easy to fall into local optimum, and slow convergence speed. To improve the performance of Genetic algorithm, an improved algorithm ECGA is proposed. In order to measure the diversity of population, the information entropy of population is calculated after fitness calculation. To speed up convergence, the consensus mechanism is presented after mutation which is used as a alternate mutation operator. And finally ECGA is applied to feature selection to test its actual effect. The experimental results show that the improved Genetic algorithm is better than the feature selection algorithm proposed in recent 2 years for the web phishing detection problem. Our algorithm achieves a average F1socre of 97%.},
   author = {Jiachen Wang},
   doi = {10.1109/CACML55074.2022.00029},
   isbn = {9781665482905},
   journal = {Proceedings - 2022 Asia Conference on Algorithms, Computing and Machine Learning, CACML 2022},
   keywords = {Data mining,Feature selection,Genetic algorithm,Information entropy,Machine learning},
   pages = {130-134},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An Improved Genetic Algorithm for Web Phishing Detection Feature Selection},
   year = {2022},
}
@article{Paliath2020,
   abstract = {Phishing emails are the first step for many of today's attacks. They come with a simple hyperlink, request for action or a full replica of an existing service or website. The goal is generally to trick the user to voluntarily give away his sensitive Information such as login credentials. Many approaches and applications have been proposed and developed to catch and filter phishing emails. However, the problem still lacks a complete and comprehensive solution. In this paper, we apply knowledge discovery principles from data cleansing, integration, selection, aggregation, data mining to knowledge extraction. We study the feature effectiveness based on Information Gain and contribute two new features to the literature. We compare six machine-learning approaches to detect phishing based on a small number of carefully chosen features. We calculate false positives, false negatives, mean absolute error, recall, precision and F-measure and achieve very low false positive and negative rates. Naive Bayes has the least true positives rate and overall Neural Networks holds the most promise for accurate phishing detection with accuracy of 99.4%.},
   author = {Suhail Paliath and Mohammad Abu Qbeitah and Mouther Aldwairi},
   doi = {10.1109/ICT49546.2020.9239589},
   isbn = {9781728165875},
   journal = {Proceedings of the 2020 27th International Conference on Telecommunications, ICT 2020},
   keywords = {Features selection,Machine learning,Phishing detection,Phishing email},
   month = {10},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Phishout: Effective phishing detection using selected features},
   year = {2020},
}
@article{Priya2020,
   abstract = {Phishing is one of the most prominent online security threat that steals the user credentials through fraudulent websites by masquerading as a legitimate website. Many online users have experienced the monitory losses due to this fraudulent attempt of getting financial credentials of user via illegitimate email. The existing phishing detection strategies mainly consider the web page features and URL characteristics. Though numerous phishing detection strategies are proposed in the literature, very few studies consider the feature selection scheme that eliminates the irrelevant or insignificant features for phishing websites detection problem. In this paper, we explored the significant features for detecting the phishing websites based on their relevance to the detection accuracy. The Gravitational Search Algorithm (GSA) is deployed as the feature selector tool to choose the most significant features from the benchmark phishing datasets. Then, the efficiency of the selected features are evaluated using different classification algorithms. From the experimental results it is stated that the features that are selected using GSA performed better than the other feature subsets for detecting the phishing websites.},
   author = {S. Priya and S. Selvakumar and R. Leela Velusamy},
   doi = {10.1109/ICIMIA48430.2020.9074837},
   isbn = {9781728141671},
   journal = {2nd International Conference on Innovative Mechanisms for Industry Applications, ICIMIA 2020 - Conference Proceedings},
   keywords = {Feature selection,Gravitational search,Neural network,Online security,Website phishing},
   month = {3},
   pages = {453-458},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Gravitational Search Based Feature Selection for Enhanced Phishing Websites Detection},
   year = {2020},
}
@article{Zaman2019,
   abstract = {Phishing is a relatively new form of network assault where a web page illegally invokes current users to request financial or personal data or passwords. This act jeopardizes the privacy of many users and consequently, ongoing research has been carried out to find detection tools and to develop existing solutions. Classifiers based on machine learning can be used to detect phishing websites effectively and therefore, various machine learning classification algorithms i.e. Naive Bayes, J48 and HNB are implemented and compared through this research. In addition, performance of a classifier combining HNB and J48 was also closely observed as a solution to the stated problem. The study proposes a novel manual feature selection approach and presents a comparative study with Filter method feature selection techniques. The dataset used in this research is collected from UCI machine learning repository, has 2670 instances and 30 attributes of website structure. The empirical result indicated that the Address bar based feature group achieved the highest accuracy in detecting phishing website. In addition, two top algorithms, HNB and J48, were developed for an integrated multi-classified process. The findings have shown that combining techniques results in 96.25% accuracy in the identification of phishing websites for all apps.},
   author = {Shihabuz Zaman and Shekh Minhaz Uddin Deep and Zul Kawsar and Md Ashaduzzaman and Ahmed Iqbal Pritom},
   doi = {10.1109/ICIET48527.2019.9290554},
   isbn = {9781728163093},
   journal = {ICIET 2019 - 2nd International Conference on Innovation in Engineering and Technology},
   keywords = {Classification,Data Mining,Feature Selection,Machine Learning,Naive Bayes,Phishing Website},
   month = {12},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Phishing Website Detection Using Effective Classifiers and Feature Selection Techniques},
   year = {2019},
}
@article{Faris2021,
   abstract = {Phishing is a type of fraud on the Internet in the form of fake web pages that mimic the original web pages to trick users into sending sensitive information to phisher. The statistics presented by APWG and Phistank show that the number of phishing websites from 2015 to 2020 tends to increase continuously. To overcome this problem, several studies have been carried out including detecting phishing web pages using various features of web pages with various methods. Unfortunately, the use of several methods is not really effective because the design and evaluation are only too focused on the achievement of detection accuracy in research, but evaluation does not represent application in the real world. Whereas a security detection device should require effectiveness, good performance, and deployable. In this study the authors evaluated several methods and proposed rules-based applications that can detect phishing more efficiently.},
   author = {Humam Faris and Setiadi Yazid},
   doi = {10.1109/IOTAIS50849.2021.9359694},
   isbn = {9781728194486},
   journal = {IoTaIS 2020 - Proceedings: 2020 IEEE International Conference on Internet of Things and Intelligence Systems},
   keywords = {URL and HTML features,information security,phishing detection,phishing webpage},
   month = {1},
   pages = {167-171},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Phishing Web Page Detection Methods: URL and HTML Features Detection},
   year = {2021},
}
@article{Dawabsheh2022,
   abstract = {Cybersecurity and phishing attacks become critical and important for the global economy because there are many areas and businesses that rely mainly on computer and Internet systems. With the dramatic increase of phishing attacks, user awareness and support remain imperative at individual and organizational levels. In this paper, an enhanced intelligent phishing detection tool is developed using deep learning from URLs. The system scans webpages and uses deep learning techniques to identify potentially harmful phishing content. The software is also supported with a blacklist of websites and some APIs for the reduction of time consumption as possible using a large dataset to train and test the system. The system is found promising and can detect phishing attacks with high and accurate rates.},
   author = {Ammar Dawabsheh and Mahmoud Jazzar and Amna Eleyan and Tarek Bejaoui and Segun Popoola},
   doi = {10.1109/SMARTNETS55823.2022.9993984},
   isbn = {9781665487580},
   journal = {2022 International Conference on Smart Applications, Communications and Networking, SmartNets 2022},
   keywords = {Phishing,URL detection,deep learning,machine learning,phishing attacks,phishing detection},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An Enhanced Phishing Detection Tool Using Deep Learning From URL},
   year = {2022},
}
@article{Sameen2020,
   abstract = {Different machine learning and deep learning-based approaches have been proposed for designing defensive mechanisms against various phishing attacks. Recently, researchers showed that phishing attacks can be performed by employing a deep neural network-based phishing URL generating system called DeepPhish. To prevent this kind of attack, we design an ensemble machine learning-based detection system called PhishHaven to identify AI-generated as well as human-crafted phishing URLs. To the best of our knowledge, this is the first study to consider detecting phishing attacks by both AI and human attackers. PhishHaven employs lexical analysis for feature extraction. To further enhance lexical analysis, we introduce URL HTML Encoding to classify URL on-the-fly and proactively compare with some of the existing methods. We also introduce a URL Hit approach to deal with tiny URLs, which is an open problem yet to be solved. Moreover, the final classification of URLs is made on an unbiased voting mechanism in PhishHaven, which aims to avoid misclassification when the number of votes is equal. To speed up the ensemble-based machine learning models, PhishHaven employs a multi-threading approach to execute the classification in parallel, leading to real-time detection. Theoretical analysis of our solution shows that (1) it can always detect tiny URLs, and (2) it can detect future AI-generated Phishing URLs based on our selected lexical features with 100% accuracy. Through experiments, we analyze our solution with a benchmark dataset of 100,000 phishing and normal URLs. The results show that PhishHaven can achieve 98.00% accuracy, outperforming the existing lexical-based human-crafted phishing URLs detection systems.},
   author = {Maria Sameen and Kyunghyun Han and Seong Oun Hwang},
   doi = {10.1109/ACCESS.2020.2991403},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {AI-generated phishing URLs,URL HTML encoding,ensemble machine learning,human-crafted phishing URLs,lexical features,multi-threading,tiny URLs,voting},
   pages = {83425-83443},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {PhishHaven - An Efficient Real-Time AI Phishing URLs Detection System},
   volume = {8},
   year = {2020},
}
@article{Alswailem2019,
   abstract = {Phishing website is one of the internet security problems that target the human vulnerabilities rather than software vulnerabilities. It can be described as the process of attracting online users to obtain their sensitive information such as usernames and passwords. In this paper, we offer an intelligent system for detecting phishing websites. The system acts as an additional functionality to an internet browser as an extension that automatically notifies the user when it detects a phishing website. The system is based on a machine learning method, particularly supervised learning. We have selected the Random Forest technique due to its good performance in classification. Our focus is to pursue a higher performance classifier by studying the features of phishing website and choose the better combination of them to train the classifier. As a result, we conclude our paper with accuracy of 98.8% and combination of 26 features.},
   author = {Amani Alswailem and Bashayr Alabdullah and Norah Alrumayh and Aram Alsedrani},
   doi = {10.1109/CAIS.2019.8769571},
   isbn = {9781728101088},
   journal = {2nd International Conference on Computer Applications and Information Security, ICCAIS 2019},
   keywords = {Random forest,URL,browser extension,machine learning,phishing features,phishing websites},
   month = {5},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Detecting Phishing Websites Using Machine Learning},
   year = {2019},
}
@article{Setyanto2022,
   abstract = {Internet users are continually exposed to phishing as cybercrime in the 21st century. The objective of phishing is to obtain sensitive information by deceiving a target and using the information for financial gain. The information may include a login detail, password, date of birth, credit card number, bank account number, and family-related information. To acquire these details, users will be directed to fill out the information on false websites based on information from emails, adverts, text messages, or website pop-ups. Examining the website&rsquo;s URL address is one method for avoiding this type of deception. Identifying the features of a phishing website URL takes specialized knowledge and investigation. Machine learning is one method that uses existing data to teach machines to distinguish between legal and phishing website URLs. In this work, we proposed a method that combines correlation and recursive feature elimination to determine which URL characteristics are useful for identifying phishing websites by gradually decreasing the number of features while maintaining accuracy value. In this paper, we use two datasets that contain 48 and 87 features. The first scenario combines power predictive score correlation and recursive feature elimination; the second scenario is the maximal information coefficient correlation and recursive feature elimination. The third scenario combines spearman correlation and recursive feature elimination. All three scenarios from the combined findings of the proposed methodologies achieve a high level of accuracy even with the smallest feature subset. For dataset 1, the accuracy value for the 10 features result is 97.06%, and for dataset 2 the accuracy value is 95.88% for 10 features.},
   author = {J ; Setyanto and A ; Alarfaj and F K ; Alreshoodi and Jimmy Moedjahedy and Arief Setyanto and Fawaz Khaled Alarfaj and Mohammed Alreshoodi},
   doi = {10.3390/FI14080229},
   issn = {1999-5903},
   issue = {8},
   journal = {Future Internet 2022, Vol. 14, Page 229},
   keywords = {correlation,feature elimination,feature selection,machine learning,phishing detection},
   month = {7},
   pages = {229},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {CCrFS: Combine Correlation Features Selection for Detecting Phishing Websites Using Machine Learning},
   volume = {14},
   url = {https://www.mdpi.com/1999-5903/14/8/229/htm https://www.mdpi.com/1999-5903/14/8/229},
   year = {2022},
}
@article{Kiruthiga2019,
   abstract = {Phishing is a common attack on credulous people by making them to disclose their unique information using counterfeit websites. The objective of phishing website URLs is to purloin the personal information like user name, passwords and online banking transactions. Phishers use the websites which are visually and semantically similar to those real websites. As technology continues to grow, phishing techniques started to progress rapidly and this needs to be prevented by using anti-phishing mechanisms to detect phishing. Machine learning is a powerful tool used to strive against phishing attacks. This paper surveys the features used for detection and detection techniques using machine learning.},
   author = {R. Kiruthiga and D. Akila},
   doi = {10.35940/ijrte.B1018.0982S1119},
   issn = {22773878},
   issue = {2 Special Issue 11},
   journal = {International Journal of Recent Technology and Engineering},
   keywords = {Detection,Machine Learning,Phishing,Phishing Websites},
   month = {9},
   pages = {111-114},
   publisher = {Blue Eyes Intelligence Engineering and Sciences Publication},
   title = {Phishing websites detection using machine learning},
   volume = {8},
   year = {2019},
}
@article{Sonowal2020,
   abstract = {Phishing remains a basic security issue in the cyberspace. In phishing, assailants steal sensitive information from victims by providing a fake site which looks like the visual clone of a legitimate site. Phishing shall be handled using various approaches. It is established that single filter methods would be insufficient to detect different categories of phishing attempts. This paper provides a multilayer model to detect phishing, titled as PhiDMA(Phishing Detection using Multi-filter Approach). The PhiDMA model incorporates five layers: Auto upgrade whitelist layer, URL features layer, Lexical signature layer, String matching layer and Accessibility Score comparison layer. A prototype implementation of the proposed PhiDMA model is built with an accessible interface so that persons with visual impairments shall access it without any barrier. The result from the experiment shows that the model is capable to detect phishing sites with an accuracy of 92.72%.},
   author = {Gunikhan Sonowal and K. S. Kuppusamy},
   doi = {10.1016/j.jksuci.2017.07.005},
   issn = {22131248},
   issue = {1},
   journal = {Journal of King Saud University - Computer and Information Sciences},
   keywords = {Accessibility,Hybrid phishing detection,Information security,Phishing,Phishing signature,Whitelist},
   month = {1},
   pages = {99-112},
   publisher = {King Saud bin Abdulaziz University},
   title = {PhiDMA – A phishing detection model with multi-filter approach},
   volume = {32},
   year = {2020},
}
@report{Kim2011,
   abstract = {The cyber attacks using web sites for a personal information sale or break down the infrastructures are increasing. To prevent cyber attacks, virtual computer systems are hired and dynamic malicious web site analysis systems are used. However the dynamic analysis systems have to setting up a targeted environment and have a threat of real attack. Unlikely the dynamic analysis system, a static malicious web site analysis system can download a web page source and analysis the web page. The static analysis algorism also has problem, the analysis time is longer than dynamic systems and need a human checking. For this reason, this journal suggest new analysis system reducing the dynamic and static system's problems using suspicious malicious web site detection with strength analysis of a JavaScript obfuscation for new hybrid analysis system.},
   author = {Byung-Ik Kim and Chae-Tae Im and Hyun-Chul Jung},
   journal = {International Journal International Journal International Journal International Journal of Advanced Science and Technology of Advanced Science and Technology of Advanced Science and Technology of Advanced Science and Technology},
   keywords = {Density,Entropy,Frequency,Malicious Web Sites,Obfuscation JavaScript},
   title = {Suspicious Malicious Web Site Detection with Strength Analysis of a JavaScript Obfuscation},
   volume = {26},
   year = {2011},
}
@generic{Basit2021,
   abstract = {In recent times, a phishing attack has become one of the most prominent attacks faced by internet users, governments, and service-providing organizations. In a phishing attack, the attacker(s) collects the client’s sensitive data (i.e., user account login details, credit/debit card numbers, etc.) by using spoofed emails or fake websites. Phishing websites are common entry points of online social engineering attacks, including numerous frauds on the websites. In such types of attacks, the attacker(s) create website pages by copying the behavior of legitimate websites and sends URL(s) to the targeted victims through spam messages, texts, or social networking. To provide a thorough understanding of phishing attack(s), this paper provides a literature review of Artificial Intelligence (AI) techniques: Machine Learning, Deep Learning, Hybrid Learning, and Scenario-based techniques for phishing attack detection. This paper also presents the comparison of different studies detecting the phishing attack for each AI technique and examines the qualities and shortcomings of these methodologies. Furthermore, this paper provides a comprehensive set of current challenges of phishing attacks and future research direction in this domain.},
   author = {Abdul Basit and Maham Zafar and Xuan Liu and Abdul Rehman Javed and Zunera Jalil and Kashif Kifayat},
   doi = {10.1007/s11235-020-00733-2},
   issn = {15729451},
   issue = {1},
   journal = {Telecommunication Systems},
   keywords = {Advanced phishing techniques,Cyberattack,Deep learning,Hybrid learning,Internet security,Machine learning,Phishing attack,Security threats},
   month = {1},
   pages = {139-154},
   publisher = {Springer},
   title = {A comprehensive survey of AI-enabled phishing attacks detection techniques},
   volume = {76},
   year = {2021},
}
@article{Cao2018,
   abstract = {Defending against distributed denial of service (DDoS) attacks in the Internet is a fundamental problem. One practical approach to addressing DDoS attacks is to redirect all destination (e.g., via DNS or BGP) to a third-party, DDoS protection-as-a-service provider (e.g., Cloudflare and Akamai), which is well provisioned and equipped with proprietary filtering mechanisms to remove attack traffic before passing the remaining traffic to the destination. Although such an approach is appealing, as it requires no modification to the existing Internet infrastructure and can scale to handle very large attacks, recent industrial interviews with more than 100 interviewees from over 10 industry segments reveal that this approach alone is not sufficient, especially for large organizations (e.g., Web hosting companies and government) that cannot afford to allow third-parity security-service providers to terminate their network connections. Instead, these organizations have to rely on their ISPs to filter attack traffic. In this paper, we discuss the challenges faced by the ISPs in order to disrupt the Internet security-service market and sketch our solutions, powered by smart contracts.},
   author = {Yuan Cao and Yuan Gao and Rongjun Tan and Qingbang Han and Zhuotao Liu},
   doi = {10.1109/ACCESS.2018.2877710},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {DDoS attacks,defense,deployability},
   pages = {66641-66648},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Understanding internet DDoS Mitigation from academic and industrial perspectives},
   volume = {6},
   year = {2018},
}
@misc{ic3InternetCrime,
	author = {},
	title = {{I}nternet {C}rime {C}omplaint {C}enter({I}{C}3) | {H}ome {P}age --- ic3.gov},
	howpublished = {url{https://www.ic3.gov/}},
	year = {2023},
	note = {[Accessed 06-May-2023]},
}
@article{das2013impact,
  title={Impact of cybercrime: Issues and challenges},
  author={Das, Sumanjit and Nayak, Tapaswini},
  journal={International journal of engineering sciences \& Emerging technologies},
  volume={6},
  number={2},
  pages={142--153},
  year={2013}
}
@article{jaishankar2007establishing,
  title={Establishing a theory of cyber crimes},
  author={Jaishankar, Karuppannan},
  journal={International Journal of Cyber Criminology},
  volume={1},
  number={2},
  pages={7--9},
  year={2007}
}
@misc{stupp_2019, title={Fraudsters used AI to mimic CEO's voice in unusual cybercrime case}, url={https://www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402}, journal={The Wall Street Journal}, publisher={Dow Jones &amp; Company}, author={Stupp, Catherine}, year={2019}, month={Aug}} 
@misc{vice_2023, title={How I broke into a bank account with an AI-generated voice}, url={https://www.vice.com/en/article/dy7axa/how-i-broke-into-a-bank-account-with-an-ai-generated-voice}, journal={VICE}, year={2023}, month={Feb}} 

@misc{refnodejs,
   author = {{Node.js Foundation}},
   title = {About | Node.js},
   url = {https://nodejs.org/en/about},
   year = {Accessed: April 22, 2023}
}

@misc{refpython,
   author = {{Python Software Foundation}},
   title = {About Python™ | Python.org},
   url = {https://www.python.org/about/},
   year = {Accessed: April 23, 2023}
}

@misc{refejs,
    title     = "EJS -- Embedded JavaScript templates",
    author = {{EmbeddedJS}},
    url = {https://ejs.co},
    year = {Accessed: April 22, 2023}
}

@misc{refbootstrap,
    title     = "Bootstrap · The most popular HTML, CSS, and JS library in the world.",
    author = {{Bootstrap}},
    url = {https://getbootstrap.com},
    year = {Accessed: April 22, 2023}
}

@misc{refjquery,
    title     = "jQuery",
    author = {{jQuery Foundation}},
    url = {https://jquery.com},
    year = {Accessed: April 22, 2023}
}